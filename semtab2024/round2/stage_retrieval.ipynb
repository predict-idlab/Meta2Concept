{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read glossary\n",
    "glossary = pd.read_csv('../data/metadata2kg/round2/r2_glossary_processed.csv')\n",
    "# read sample metadata\n",
    "metadata = pd.read_json('../data/metadata2kg/round2/r2_test_metadata.jsonl', lines=True)\n",
    "# concat index number with id to make it unique\n",
    "metadata['id'] = metadata.index.astype(str) + '_' + metadata['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glossary descriptions\n",
    "with open('metadata_descriptions_cleaned.json', 'r') as f:\n",
    "    metadata_desc = json.load(f)\n",
    "metadata['emb_desc'] = metadata['id'].map(metadata_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from constants import API_KEY_OPENAI, API_KEY_DEEPINFRA\n",
    "\n",
    "client = OpenAI(api_key=API_KEY_OPENAI)\n",
    "\n",
    "glossary_embeddings_openai = []\n",
    "for i in range(0, len(glossary), 512):\n",
    "    print(i)\n",
    "    emb = client.embeddings.create(input = glossary['desc'].values[i:i+512].tolist(), model='text-embedding-3-large').data\n",
    "    emb = [e.embedding for e in emb]\n",
    "    glossary_embeddings_openai.append(emb)\n",
    "glossary_embeddings_openai = np.concatenate(glossary_embeddings_openai)\n",
    "\n",
    "metadata_embeddings_openai = []\n",
    "for i in range(0, len(metadata), 512):\n",
    "    print(i)\n",
    "    emb = client.embeddings.create(input = metadata['emb_desc'].values[i:i+512].tolist(), model='text-embedding-3-large').data\n",
    "    emb = [e.embedding for e in emb]\n",
    "    metadata_embeddings_openai.append(emb)\n",
    "metadata_embeddings_openai = np.concatenate(metadata_embeddings_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary['embeddings_openai'] = glossary_embeddings_openai.tolist()\n",
    "metadata['embeddings_openai'] = metadata_embeddings_openai.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_score = []\n",
    "\n",
    "g = np.concatenate(glossary['embeddings_openai'].values).reshape(-1, 3072)\n",
    "for d in metadata.to_dict('records'):\n",
    "    e = d['embeddings_openai']\n",
    "    sim_score.append(np.dot(g, e)) # cosine similarity\n",
    "sim_score = np.array(sim_score).reshape(len(metadata), len(glossary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_openai = {}\n",
    "\n",
    "for i, d in enumerate(metadata.to_dict('records')):\n",
    "    sim = sim_score[i,:]\n",
    "    idx = np.argsort(sim.flatten())[::-1]\n",
    "    orig_idx = np.tile(glossary['id'].values, len(sim))\n",
    "    rank_ids = orig_idx[idx]\n",
    "    rank_ids = list(dict.fromkeys(rank_ids))\n",
    "    rank_openai[d['id']] = rank_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"What is the best description of column {column} in the table '{table_name}' with columns {table_columns}?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_openai = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from rank_gpt import sliding_windows\n",
    "\n",
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def fn(chunk):\n",
    "    for i, row in chunk.iterrows():\n",
    "        if row['id'] in rerank_openai:\n",
    "            continue\n",
    "\n",
    "        print(row['id'])\n",
    "        top_hits = rank_openai[row['id']][:150]\n",
    "        \n",
    "        item = {\n",
    "            'query': query.format(column=row['label'], \n",
    "                                table_columns=row['table_columns'], \n",
    "                                table_name=row['table_name']),\n",
    "            'hits': [{'id': row['id'], 'content': row['label'] + \", \" + row['desc']} for i, row in glossary.iloc[top_hits].iterrows()]\n",
    "        }\n",
    "\n",
    "        new_item = sliding_windows(item, rank_start=0, rank_end=len(top_hits), window_size=20, step=10, model_name=\"meta-llama/Meta-Llama-3-70B-Instruct\", api_key=API_KEY_DEEPINFRA)\n",
    "        ranking = [hit['id'] for hit in new_item['hits']]\n",
    "        rerank_openai[row['id']] = ranking\n",
    "\n",
    "n_clients = 20\n",
    "for i in range(n_clients):\n",
    "    fn(metadata[metadata.index%n_clients==i])\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# create mapping file\n",
    "mapping = []\n",
    "for i, d in enumerate(metadata.to_dict('records')):\n",
    "    # parse table as json object and get id\n",
    "    id = d['id']\n",
    "    mappings = []\n",
    "\n",
    "    if id in rerank_openai:\n",
    "        for top in rerank_openai[id]: #rank\n",
    "            mappings.append({'id': str(int(top)), 'score': 1.0})\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    mapping.append({'id': '_'.join(id.split('_')[1:]), 'mappings': mappings})\n",
    "\n",
    "for table in mapping:\n",
    "    print(table)\n",
    "\n",
    "# write mapping file\n",
    "with open('mapping_rerank.jsonl', 'w') as f:\n",
    "    for m in mapping:\n",
    "        f.write(json.dumps(m) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6648d82896bd203fd466e78bea17536dc66c69ff4a963dcb65bdd261657c162"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
